{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 2]) tensor([[[[ 0.0000,  0.0000],\n",
      "          [ 1.2818,  3.5853],\n",
      "          [ 0.7203,  1.6506]],\n",
      "\n",
      "         [[-1.2818, -3.5853],\n",
      "          [ 0.0000,  0.0000],\n",
      "          [-0.5616, -1.9347]],\n",
      "\n",
      "         [[-0.7203, -1.6506],\n",
      "          [ 0.5616,  1.9347],\n",
      "          [ 0.0000,  0.0000]]]])\n",
      "tensor([[[-0.2038,  2.7274],\n",
      "         [-1.4856, -0.8579],\n",
      "         [-0.9240,  1.0768]]])\n",
      "tensor([[1.2818, 3.5853]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(1, 3, 2)\n",
    "\n",
    "diffs = a.unsqueeze(2) - a \n",
    "\n",
    "print(diffs.shape, diffs)\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(a[:, 0, :] - a[:, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops.layers.torch import Reduce\n",
    "from pytorch3d.ops import knn_points\n",
    "\n",
    "\n",
    "#ARPE: Absolute Relative Position Encoding\n",
    "class ARPE(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=32, npoints=1024):\n",
    "        super(ARPE, self).__init__()\n",
    "\n",
    "        N0 = 512\n",
    "        k0 = 32\n",
    "        #self.k = int(k0 * npoints / N0)\n",
    "        self.k = 3\n",
    "\n",
    "\n",
    "        self.lin1 = nn.Linear(2*in_channels, 2*in_channels)\n",
    "        self.lin2 = nn.Linear(2*in_channels, out_channels)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(2*in_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.max_pooling_layer = Reduce('bn k f -> bn 1 f', 'max')\n",
    "     \n",
    "    def forward(self, x):\n",
    "    \n",
    "        B, N, C = x.shape  # B: batch size, N: number of points, C: channels\n",
    "\n",
    "        knn = knn_points(x, x, K=self.k, return_nn=True)[2] # B, N, K, C\n",
    "\n",
    "        diffs = x.unsqueeze(2) - knn  # B, N, K, C\n",
    "\n",
    "        x = torch.cat([x.unsqueeze(2).repeat(1, 1, self.k, 1), diffs], dim=-1) # B, N, K, 2*C\n",
    "        x = F.elu(self.bn1(self.lin1(x.view(B*N, self.k, 2*C)).transpose(1,2)).transpose(1,2)) # B*N, K, 2*C\n",
    "        x = self.max_pooling_layer(x).squeeze(2) # B*N, 1, 2*C -> B*N, 2*C\n",
    "        x = F.elu(self.bn2(self.lin2(x.view(B, N, 2*C)).transpose(1,2)).transpose(1,2)) # B, N, out_channels\n",
    "\n",
    "        return x # B, N, 2*C\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn(32, 1024, 3)\n",
    "arpe = ARPE()\n",
    "y = arpe(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = torch.Tensor([[[0,1,0],[1,1,0],[5,4,2],[1,-1,0],[5,4,5]]])\n",
    "\n",
    "#print(test1.shape, test1)\n",
    "\n",
    "res1 = arpe(test1)\n",
    "\n",
    "#print(res1.shape, res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "         [10., 11., 12., 13., 14., 15.]]]) \n",
      " tensor([[[ 0.,  2.,  4.,  1.,  3.,  5.],\n",
      "         [10., 12., 14., 11., 13., 15.]]])\n"
     ]
    }
   ],
   "source": [
    "def channel_shuffle(x, groups):\n",
    "    B, N, C = x.shape\n",
    "    x = x.reshape(B,N,C//groups,groups).permute(0,1,3,2).reshape(B,N,C)\n",
    "    return x\n",
    "\n",
    "x = torch.Tensor([[[0,1,2,3,4,5],[10,11,12,13,14,15]]])\n",
    "print(x, \"\\n\",channel_shuffle(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 64]) tensor([[[ 1.2237, -0.8037,  1.3921,  ..., -1.0365,  0.4913,  0.2581],\n",
      "         [ 2.7352,  0.6385, -1.3255,  ..., -0.7104,  0.4561, -0.2360],\n",
      "         [ 0.4152,  0.9576,  0.9140,  ..., -2.3849,  0.0664,  1.4169],\n",
      "         ...,\n",
      "         [ 1.7712,  1.1960, -1.4218,  ...,  0.8140,  1.7724,  1.4896],\n",
      "         [ 3.6019,  0.3345,  0.0275,  ...,  0.0729,  2.6080, -0.3425],\n",
      "         [ 0.9314, -0.4408, -1.2867,  ..., -1.8996, -0.0488,  0.0482]],\n",
      "\n",
      "        [[-0.1493,  0.3500,  1.5321,  ..., -2.3826, -0.2346, -0.6107],\n",
      "         [-0.3187, -0.3732,  1.5537,  ..., -0.5482, -1.2268, -1.2083],\n",
      "         [ 0.1585, -0.7358,  0.8468,  ...,  0.4084, -1.1123,  0.2931],\n",
      "         ...,\n",
      "         [-0.0174,  0.1714,  0.4648,  ..., -1.2219, -0.6911, -1.3813],\n",
      "         [-0.6678,  1.8194,  0.9540,  ...,  0.0832,  0.4032, -0.8266],\n",
      "         [-0.8656,  0.1114,  0.3085,  ..., -0.4639, -1.0562,  0.8100]],\n",
      "\n",
      "        [[-0.8138,  0.4247, -1.1904,  ..., -0.4541,  0.3031,  1.0193],\n",
      "         [ 0.6234, -0.1794,  0.1226,  ..., -0.3260, -0.1642,  0.6109],\n",
      "         [-1.6404, -0.9694, -0.8371,  ..., -0.6862, -0.6746, -0.4564],\n",
      "         ...,\n",
      "         [-0.9562, -0.1769, -0.2280,  ...,  0.8641,  0.8766,  2.4568],\n",
      "         [ 0.5556,  0.5907,  0.8035,  ...,  0.9298,  0.2589,  0.8747],\n",
      "         [-1.2506, -0.2821, -0.9162,  ...,  2.2163,  0.3998,  0.2499]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2903,  0.7941,  0.3419,  ...,  1.6914, -1.7532, -1.2936],\n",
      "         [ 0.2036,  0.2052,  0.5185,  ..., -0.5382, -1.4478, -0.0228],\n",
      "         [-0.1383, -0.0482,  3.2086,  ..., -0.1400, -1.8720, -0.1463],\n",
      "         ...,\n",
      "         [-0.0717,  0.9018,  2.2567,  ...,  0.1432, -0.0036, -1.3958],\n",
      "         [-1.0897,  0.8103,  1.1162,  ...,  1.1770, -1.4622, -1.2794],\n",
      "         [-0.2079, -0.5350,  0.4414,  ...,  0.3552,  1.2170, -1.4988]],\n",
      "\n",
      "        [[ 0.4887,  0.8608, -0.5448,  ..., -1.8581, -0.9524,  0.3094],\n",
      "         [-0.1871,  0.5320,  0.1883,  ..., -0.8353,  0.5876,  0.3867],\n",
      "         [ 1.4788,  0.5217,  1.0592,  ..., -0.1798, -1.1948,  0.2787],\n",
      "         ...,\n",
      "         [-0.1251,  0.5309,  1.9180,  ..., -2.0590, -0.6717,  0.0412],\n",
      "         [ 1.3303,  0.2339,  0.9905,  ...,  0.4170,  0.5928, -0.3443],\n",
      "         [-0.9380,  1.5553,  0.4129,  ...,  0.2112, -0.0506,  1.6992]],\n",
      "\n",
      "        [[-1.2925,  0.2428, -0.9050,  ..., -0.0379,  0.1562,  0.0528],\n",
      "         [ 0.3029, -0.0437,  0.4468,  ...,  1.0389, -0.5028, -0.3559],\n",
      "         [ 1.5567,  1.1861, -1.9311,  ..., -0.3371, -0.2700,  0.8601],\n",
      "         ...,\n",
      "         [-1.2468,  0.6247, -0.4730,  ...,  1.3199,  0.1285, -0.1971],\n",
      "         [-0.6878,  0.6019, -1.8563,  ..., -0.4297, -0.6480,  0.1179],\n",
      "         [ 1.0108, -1.5062, -1.7062,  ...,  0.6468, -0.0454, -0.0733]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class GSA(nn.Module):\n",
    "    def __init__(self, channels = 64, groups=1) -> None:\n",
    "        super(GSA, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.groups = groups\n",
    "        assert self.channels % self.groups == 0, \"C must be divisible by groups\"\n",
    "        self.cg = self.channels // self.groups\n",
    "        self.linears = [nn.Linear(self.cg, self.cg) for _ in range(self.groups)]\n",
    "        self.gn = nn.GroupNorm(self.groups, self.channels)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        xin = x # B, N, C\n",
    "\n",
    "        #grouped_x = x.reshape(B, N, C//self.groups, self.groups) # B, N, C//groups, groups\n",
    "\n",
    "        #Si puÃ² vettorizzare?\n",
    "        x_g =[]\n",
    "        for i in range(self.groups):\n",
    "            x = self.linears[i](xin[:,:,i*self.cg:(i+1)*self.cg]) # B, N, C//groups\n",
    "            x = F.scaled_dot_product_attention(x,x,F.elu(x), attn_mask=mask)\n",
    "            x_g.append(x)\n",
    "        x = torch.cat(x_g, dim=-1) # B, N, C\n",
    "\n",
    "        x = self.gn((channel_shuffle(x, self.groups) + xin).transpose(1,2)).transpose(1,2) # B, N, C\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "gsa = GSA(groups=2)\n",
    "x = torch.randn(32, 1024, 64)\n",
    "mask = torch.ones(32, 1024, 1024).bool()\n",
    "y = gsa(x, mask=mask)\n",
    "#print(y.shape, y)\n",
    "mask2 = torch.zeros(32, 1024, 1024).bool()\n",
    "mask2[:,:,0] = True   \n",
    "y2 = gsa(x, mask=mask2)\n",
    "print(y2.shape, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_conv(x)\n\u001b[1;32m     29\u001b[0m dp \u001b[39m=\u001b[39m DropPredictor(\u001b[39m64\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m64\u001b[39m)\n\u001b[1;32m     31\u001b[0m policy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m y \u001b[39m=\u001b[39m dp(x, policy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class DropPredictor(nn.Module):\n",
    "    \"\"\" Computes the log-probabilities of dropping a token, adapted from PredictorLG here:\n",
    "    https://github.com/raoyongming/DynamicViT/blob/48ac52643a637ed5a4cf7c7d429dcf17243794cd/models/dyvit.py#L287 \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.in_conv = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim // 2, embed_dim // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim // 4, 2),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, policy):\n",
    "        x = self.in_conv(x)\n",
    "        B, N, C = x.size()\n",
    "        local_x = x[:,:, :C//2]\n",
    "        global_x = (x[:,:, C//2:] * policy).sum(dim=1, keepdim=True) / (torch.sum(policy, dim=1, keepdim=True)+1e-20)\n",
    "        x = torch.cat([local_x, global_x.expand(B, N, C//2)], dim=-1)\n",
    "        return self.out_conv(x)\n",
    "    \n",
    "dp = DropPredictor(64)\n",
    "x = torch.randn(2, 5, 64)\n",
    "policy = torch.ones(2, 5, 1)\n",
    "y = dp(x, policy)\n",
    "print(y.shape, y)\n",
    "y = torch.log(y + 1e-8)\n",
    "decision = F.gumbel_softmax(y, tau=0.00001, hard=True, dim=-1)[:,:,1:2]*policy\n",
    "print(decision.shape, decision)\n",
    "mask = decision * decision.transpose(1,2)\n",
    "print(mask.shape, mask)\n",
    "\n",
    "gsa = GSA(groups=2)\n",
    "x = torch.randn(32, 1024, 64)\n",
    "mask = torch.ones(32, 1024, 1024).bool()\n",
    "y = gsa(x, mask=mask)\n",
    "print(y.shape, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cg:  64\n",
      "cg:  64\n",
      "cg:  64\n",
      "cg:  64\n",
      "x shape:  torch.Size([32, 64])\n",
      "torch.Size([32, 40]) tensor([[-0.1468, -0.3464, -0.6327,  ...,  1.0956, -0.5540, -0.2624],\n",
      "        [ 0.9423,  0.3504, -0.6428,  ..., -0.3769,  0.0230, -0.6537],\n",
      "        [ 0.3301, -0.8159,  1.7425,  ...,  0.9700,  0.5318, -1.5326],\n",
      "        ...,\n",
      "        [-0.2668, -0.2902,  0.4691,  ...,  0.2406, -0.5672,  0.4251],\n",
      "        [ 0.6645,  0.3186,  0.1869,  ...,  0.1530,  0.9427, -0.7333],\n",
      "        [-0.3446,  0.4143, -0.1941,  ...,  0.9127,  0.2795,  0.0604]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import torch\n",
    "from model import Adapt_classf\n",
    "\n",
    "adapt = Adapt_classf(embed_dim=64, n_classes=40, n_points=1024, n_blocks=4, drop_loc=[2], drop_target=[0.5])\n",
    "x = torch.randn(32, 1024, 3)\n",
    "y = adapt(x)\n",
    "print(y.shape, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "B=5\n",
    "torch.eye(3).repeat(B,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5597],\n",
      "         [-0.8962],\n",
      "         [-0.0744],\n",
      "         [-0.0450],\n",
      "         [-0.0339]],\n",
      "\n",
      "        [[-0.8471],\n",
      "         [-0.5244],\n",
      "         [-2.6348],\n",
      "         [-3.1239],\n",
      "         [-3.4022]]]) tensor([[[0.0000],\n",
      "         [0.0000],\n",
      "         [0.3100],\n",
      "         [0.3394],\n",
      "         [0.3506]],\n",
      "\n",
      "        [[0.3387],\n",
      "         [0.6613],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2698802/3194466558.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = F.softmax(torch.randn(2, 5, 1))\n"
     ]
    }
   ],
   "source": [
    "from entmax import sparsemax\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = F.softmax(torch.randn(2, 5, 1))\n",
    "\n",
    "b=torch.log(a + 1e-8)\n",
    "#b = a\n",
    "print(b,sparsemax(b, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([0,0.0002,0.3])\n",
    "\n",
    "print(a.bool())\n",
    "\n",
    "\n",
    "b = torch.randint(4, size=(1,))\n",
    "print(b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "tensor([0.3698, 0.3854, 0.4404, 0.4311], grad_fn=<CatBackward0>)\n",
      "tensor([[ 0.0441, -0.0739]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "#simple linear layer\n",
    "lin = nn.Linear(2, 1)\n",
    "\n",
    "x = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = [0,1,1,0]\n",
    "\n",
    "print(lin.weight.grad)\n",
    "\n",
    "preds = torch.Tensor([])\n",
    "for i in range(4):\n",
    "    preds = torch.cat([preds, F.sigmoid(lin(x[i,:]))])\n",
    "\n",
    "print(lin.weight.grad)\n",
    "print(preds)\n",
    "\n",
    "loss = F.binary_cross_entropy(preds, torch.Tensor(y))\n",
    "loss.backward()\n",
    "\n",
    "print(lin.weight.grad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entmax import sparsemax, entmax15, entmax_bisect\n",
    "import torch\n",
    "\n",
    "a = torch.randn(100)\n",
    "print(a,sparsemax(a, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adapt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
