{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 2]) tensor([[[[ 0.0000,  0.0000],\n",
      "          [ 1.2818,  3.5853],\n",
      "          [ 0.7203,  1.6506]],\n",
      "\n",
      "         [[-1.2818, -3.5853],\n",
      "          [ 0.0000,  0.0000],\n",
      "          [-0.5616, -1.9347]],\n",
      "\n",
      "         [[-0.7203, -1.6506],\n",
      "          [ 0.5616,  1.9347],\n",
      "          [ 0.0000,  0.0000]]]])\n",
      "tensor([[[-0.2038,  2.7274],\n",
      "         [-1.4856, -0.8579],\n",
      "         [-0.9240,  1.0768]]])\n",
      "tensor([[1.2818, 3.5853]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(1, 3, 2)\n",
    "\n",
    "diffs = a.unsqueeze(2) - a \n",
    "\n",
    "print(diffs.shape, diffs)\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(a[:, 0, :] - a[:, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops.layers.torch import Reduce\n",
    "from pytorch3d.ops import knn_points\n",
    "\n",
    "\n",
    "#ARPE: Absolute Relative Position Encoding\n",
    "class ARPE(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=32, npoints=1024):\n",
    "        super(ARPE, self).__init__()\n",
    "\n",
    "        N0 = 512\n",
    "        k0 = 32\n",
    "        #self.k = int(k0 * npoints / N0)\n",
    "        self.k = 3\n",
    "\n",
    "\n",
    "        self.lin1 = nn.Linear(2*in_channels, 2*in_channels)\n",
    "        self.lin2 = nn.Linear(2*in_channels, out_channels)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(2*in_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.max_pooling_layer = Reduce('bn k f -> bn 1 f', 'max')\n",
    "     \n",
    "    def forward(self, x):\n",
    "    \n",
    "        B, N, C = x.shape  # B: batch size, N: number of points, C: channels\n",
    "\n",
    "        knn = knn_points(x, x, K=self.k, return_nn=True)[2] # B, N, K, C\n",
    "\n",
    "        diffs = x.unsqueeze(2) - knn  # B, N, K, C\n",
    "\n",
    "        x = torch.cat([x.unsqueeze(2).repeat(1, 1, self.k, 1), diffs], dim=-1) # B, N, K, 2*C\n",
    "        x = F.elu(self.bn1(self.lin1(x.view(B*N, self.k, 2*C)).transpose(1,2)).transpose(1,2)) # B*N, K, 2*C\n",
    "        x = self.max_pooling_layer(x).squeeze(2) # B*N, 1, 2*C -> B*N, 2*C\n",
    "        x = F.elu(self.bn2(self.lin2(x.view(B, N, 2*C)).transpose(1,2)).transpose(1,2)) # B, N, out_channels\n",
    "\n",
    "        return x # B, N, 2*C\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn(32, 1024, 3)\n",
    "arpe = ARPE()\n",
    "y = arpe(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = torch.Tensor([[[0,1,0],[1,1,0],[5,4,2],[1,-1,0],[5,4,5]]])\n",
    "\n",
    "#print(test1.shape, test1)\n",
    "\n",
    "res1 = arpe(test1)\n",
    "\n",
    "#print(res1.shape, res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "         [10., 11., 12., 13., 14., 15.]]]) \n",
      " tensor([[[ 0.,  2.,  4.,  1.,  3.,  5.],\n",
      "         [10., 12., 14., 11., 13., 15.]]])\n"
     ]
    }
   ],
   "source": [
    "def channel_shuffle(x, groups):\n",
    "    B, N, C = x.shape\n",
    "    x = x.reshape(B,N,C//groups,groups).permute(0,1,3,2).reshape(B,N,C)\n",
    "    return x\n",
    "\n",
    "x = torch.Tensor([[[0,1,2,3,4,5],[10,11,12,13,14,15]]])\n",
    "print(x, \"\\n\",channel_shuffle(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 64]) tensor([[[ 1.2237, -0.8037,  1.3921,  ..., -1.0365,  0.4913,  0.2581],\n",
      "         [ 2.7352,  0.6385, -1.3255,  ..., -0.7104,  0.4561, -0.2360],\n",
      "         [ 0.4152,  0.9576,  0.9140,  ..., -2.3849,  0.0664,  1.4169],\n",
      "         ...,\n",
      "         [ 1.7712,  1.1960, -1.4218,  ...,  0.8140,  1.7724,  1.4896],\n",
      "         [ 3.6019,  0.3345,  0.0275,  ...,  0.0729,  2.6080, -0.3425],\n",
      "         [ 0.9314, -0.4408, -1.2867,  ..., -1.8996, -0.0488,  0.0482]],\n",
      "\n",
      "        [[-0.1493,  0.3500,  1.5321,  ..., -2.3826, -0.2346, -0.6107],\n",
      "         [-0.3187, -0.3732,  1.5537,  ..., -0.5482, -1.2268, -1.2083],\n",
      "         [ 0.1585, -0.7358,  0.8468,  ...,  0.4084, -1.1123,  0.2931],\n",
      "         ...,\n",
      "         [-0.0174,  0.1714,  0.4648,  ..., -1.2219, -0.6911, -1.3813],\n",
      "         [-0.6678,  1.8194,  0.9540,  ...,  0.0832,  0.4032, -0.8266],\n",
      "         [-0.8656,  0.1114,  0.3085,  ..., -0.4639, -1.0562,  0.8100]],\n",
      "\n",
      "        [[-0.8138,  0.4247, -1.1904,  ..., -0.4541,  0.3031,  1.0193],\n",
      "         [ 0.6234, -0.1794,  0.1226,  ..., -0.3260, -0.1642,  0.6109],\n",
      "         [-1.6404, -0.9694, -0.8371,  ..., -0.6862, -0.6746, -0.4564],\n",
      "         ...,\n",
      "         [-0.9562, -0.1769, -0.2280,  ...,  0.8641,  0.8766,  2.4568],\n",
      "         [ 0.5556,  0.5907,  0.8035,  ...,  0.9298,  0.2589,  0.8747],\n",
      "         [-1.2506, -0.2821, -0.9162,  ...,  2.2163,  0.3998,  0.2499]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2903,  0.7941,  0.3419,  ...,  1.6914, -1.7532, -1.2936],\n",
      "         [ 0.2036,  0.2052,  0.5185,  ..., -0.5382, -1.4478, -0.0228],\n",
      "         [-0.1383, -0.0482,  3.2086,  ..., -0.1400, -1.8720, -0.1463],\n",
      "         ...,\n",
      "         [-0.0717,  0.9018,  2.2567,  ...,  0.1432, -0.0036, -1.3958],\n",
      "         [-1.0897,  0.8103,  1.1162,  ...,  1.1770, -1.4622, -1.2794],\n",
      "         [-0.2079, -0.5350,  0.4414,  ...,  0.3552,  1.2170, -1.4988]],\n",
      "\n",
      "        [[ 0.4887,  0.8608, -0.5448,  ..., -1.8581, -0.9524,  0.3094],\n",
      "         [-0.1871,  0.5320,  0.1883,  ..., -0.8353,  0.5876,  0.3867],\n",
      "         [ 1.4788,  0.5217,  1.0592,  ..., -0.1798, -1.1948,  0.2787],\n",
      "         ...,\n",
      "         [-0.1251,  0.5309,  1.9180,  ..., -2.0590, -0.6717,  0.0412],\n",
      "         [ 1.3303,  0.2339,  0.9905,  ...,  0.4170,  0.5928, -0.3443],\n",
      "         [-0.9380,  1.5553,  0.4129,  ...,  0.2112, -0.0506,  1.6992]],\n",
      "\n",
      "        [[-1.2925,  0.2428, -0.9050,  ..., -0.0379,  0.1562,  0.0528],\n",
      "         [ 0.3029, -0.0437,  0.4468,  ...,  1.0389, -0.5028, -0.3559],\n",
      "         [ 1.5567,  1.1861, -1.9311,  ..., -0.3371, -0.2700,  0.8601],\n",
      "         ...,\n",
      "         [-1.2468,  0.6247, -0.4730,  ...,  1.3199,  0.1285, -0.1971],\n",
      "         [-0.6878,  0.6019, -1.8563,  ..., -0.4297, -0.6480,  0.1179],\n",
      "         [ 1.0108, -1.5062, -1.7062,  ...,  0.6468, -0.0454, -0.0733]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class GSA(nn.Module):\n",
    "    def __init__(self, channels = 64, groups=1) -> None:\n",
    "        super(GSA, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.groups = groups\n",
    "        assert self.channels % self.groups == 0, \"C must be divisible by groups\"\n",
    "        self.cg = self.channels // self.groups\n",
    "        self.linears = [nn.Linear(self.cg, self.cg) for _ in range(self.groups)]\n",
    "        self.gn = nn.GroupNorm(self.groups, self.channels)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        xin = x # B, N, C\n",
    "\n",
    "        #grouped_x = x.reshape(B, N, C//self.groups, self.groups) # B, N, C//groups, groups\n",
    "\n",
    "        #Si pu√≤ vettorizzare?\n",
    "        x_g =[]\n",
    "        for i in range(self.groups):\n",
    "            x = self.linears[i](xin[:,:,i*self.cg:(i+1)*self.cg]) # B, N, C//groups\n",
    "            x = F.scaled_dot_product_attention(x,x,F.elu(x), attn_mask=mask)\n",
    "            x_g.append(x)\n",
    "        x = torch.cat(x_g, dim=-1) # B, N, C\n",
    "\n",
    "        x = self.gn((channel_shuffle(x, self.groups) + xin).transpose(1,2)).transpose(1,2) # B, N, C\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "gsa = GSA(groups=2)\n",
    "x = torch.randn(32, 1024, 64)\n",
    "mask = torch.ones(32, 1024, 1024).bool()\n",
    "y = gsa(x, mask=mask)\n",
    "#print(y.shape, y)\n",
    "mask2 = torch.zeros(32, 1024, 1024).bool()\n",
    "mask2[:,:,0] = True   \n",
    "y2 = gsa(x, mask=mask2)\n",
    "print(y2.shape, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 2]) tensor([[[0.4374, 0.5626],\n",
      "         [0.4495, 0.5505],\n",
      "         [0.4386, 0.5614],\n",
      "         [0.4375, 0.5625],\n",
      "         [0.4488, 0.5512]],\n",
      "\n",
      "        [[0.4362, 0.5638],\n",
      "         [0.4271, 0.5729],\n",
      "         [0.4478, 0.5522],\n",
      "         [0.4457, 0.5543],\n",
      "         [0.4344, 0.5656]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2, 5, 1]) tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [1.]],\n",
      "\n",
      "        [[0.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [1.],\n",
      "         [0.]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 5, 5]) tensor([[[1., 1., 1., 0., 1.],\n",
      "         [1., 1., 1., 0., 1.],\n",
      "         [1., 1., 1., 0., 1.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([32, 1024, 64]) tensor([[[-0.2808,  0.7440,  0.2651,  ...,  0.2239,  0.9012,  1.2596],\n",
      "         [ 0.9152, -1.6525,  0.2137,  ...,  0.1134, -0.0055,  0.9538],\n",
      "         [ 1.4099, -0.3707,  0.8172,  ...,  2.1472, -1.3497, -1.1939],\n",
      "         ...,\n",
      "         [-0.9240, -1.2738,  0.0153,  ..., -0.1322, -0.9876,  0.3964],\n",
      "         [-0.8364,  1.2040, -0.4403,  ...,  0.7055, -0.5106,  0.4022],\n",
      "         [ 0.8758,  0.1757,  1.5541,  ..., -0.4186, -0.9432,  0.8299]],\n",
      "\n",
      "        [[ 0.1028, -0.6295, -0.3563,  ..., -1.8152, -1.0379, -0.4024],\n",
      "         [ 0.6685,  1.0264, -0.3099,  ..., -0.9045, -0.2330,  1.1939],\n",
      "         [-1.7142,  0.3094,  1.4410,  ...,  1.8746, -1.8258, -0.9827],\n",
      "         ...,\n",
      "         [ 0.3528,  1.1576, -0.0475,  ...,  0.2884, -0.1397,  0.1654],\n",
      "         [-0.3062, -0.2045,  1.6112,  ...,  0.7921, -1.0556,  0.8608],\n",
      "         [ 2.6108,  1.5177, -1.4757,  ...,  0.2540, -1.1285,  0.1620]],\n",
      "\n",
      "        [[ 0.2352, -0.8727, -0.6060,  ..., -0.5793,  0.1166,  2.0824],\n",
      "         [ 0.4297,  0.1372,  0.9196,  ..., -1.3956,  0.9876, -0.6580],\n",
      "         [-1.3404, -1.7114,  1.4615,  ...,  0.0521, -0.9072, -1.9606],\n",
      "         ...,\n",
      "         [-1.1389,  0.8778, -0.5902,  ..., -0.6785, -1.0980,  0.9505],\n",
      "         [ 0.8661,  0.2375,  0.7032,  ..., -0.8282,  0.1086, -0.3885],\n",
      "         [ 0.0451,  0.2988, -0.5573,  ...,  0.0426,  1.1610,  0.4116]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0622, -0.5110,  0.0195,  ..., -0.0358, -0.2023, -1.7177],\n",
      "         [-1.3902, -0.0099, -0.0622,  ..., -1.0322, -1.9506,  0.4326],\n",
      "         [ 1.4041, -1.4267, -0.4037,  ...,  0.1562, -1.1606, -0.1313],\n",
      "         ...,\n",
      "         [-0.8606, -0.0459,  1.2811,  ...,  0.2827,  0.5506, -0.6485],\n",
      "         [-1.3948, -1.3824, -0.0152,  ...,  0.9056,  0.4678, -1.1522],\n",
      "         [ 1.0215,  0.0707, -0.1883,  ..., -0.5145, -0.0693,  1.1731]],\n",
      "\n",
      "        [[-0.2573, -0.7853,  0.6084,  ...,  0.2481,  0.7463,  0.4349],\n",
      "         [-0.3409,  2.0532,  0.4281,  ..., -0.4349, -1.5604, -0.1628],\n",
      "         [-0.1602, -0.9905,  0.9015,  ...,  1.8918, -0.9926, -0.2266],\n",
      "         ...,\n",
      "         [-0.1977, -0.4148, -0.5115,  ...,  0.7858, -0.8397,  0.0145],\n",
      "         [-1.4127, -0.0481, -0.2476,  ..., -0.7731,  0.0186, -0.4154],\n",
      "         [-0.8539,  0.8995, -0.4620,  ..., -0.0299, -0.3534,  0.6139]],\n",
      "\n",
      "        [[-0.2609,  0.3544, -0.3614,  ...,  1.0086,  0.7980, -1.3436],\n",
      "         [ 0.7330, -0.1853, -0.7692,  ..., -0.6334, -0.5799,  2.9534],\n",
      "         [-0.3589,  0.1061, -0.2101,  ...,  0.5308, -0.8834, -0.0443],\n",
      "         ...,\n",
      "         [ 0.2343, -0.3705,  0.5428,  ...,  0.5455,  0.3044, -0.5086],\n",
      "         [ 0.1936,  0.4830,  0.9380,  ...,  0.5797,  2.6348,  0.5242],\n",
      "         [ 0.3896, -0.4907, -0.9620,  ..., -1.3739, -0.4288, -0.0827]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class DropPredictor(nn.Module):\n",
    "    \"\"\" Computes the log-probabilities of dropping a token, adapted from PredictorLG here:\n",
    "    https://github.com/raoyongming/DynamicViT/blob/48ac52643a637ed5a4cf7c7d429dcf17243794cd/models/dyvit.py#L287 \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.in_conv = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim // 2, embed_dim // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim // 4, 2),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, policy):\n",
    "        x = self.in_conv(x)\n",
    "        B, N, C = x.size()\n",
    "        local_x = x[:,:, :C//2]\n",
    "        global_x = (x[:,:, C//2:] * policy).sum(dim=1, keepdim=True) / (torch.sum(policy, dim=1, keepdim=True)+1e-20)\n",
    "        x = torch.cat([local_x, global_x.expand(B, N, C//2)], dim=-1)\n",
    "        return self.out_conv(x)\n",
    "    \n",
    "dp = DropPredictor(64)\n",
    "x = torch.randn(2, 5, 64)\n",
    "policy = torch.ones(2, 5, 1)\n",
    "y = dp(x, policy)\n",
    "print(y.shape, y)\n",
    "y = torch.log(y + 1e-8)\n",
    "decision = F.gumbel_softmax(y, tau=0.00001, hard=True, dim=-1)[:,:,1:2]*policy\n",
    "print(decision.shape, decision)\n",
    "mask = decision * decision.transpose(1,2)\n",
    "print(mask.shape, mask)\n",
    "\n",
    "gsa = GSA(groups=2)\n",
    "x = torch.randn(32, 1024, 64)\n",
    "mask = torch.ones(32, 1024, 1024).bool()\n",
    "y = gsa(x, mask=mask)\n",
    "print(y.shape, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'AdaPT_reloaded'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m/home/alebai/Projects/AdaPT_reloaded\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mAdaPT_reloaded\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaPT\n\u001b[1;32m      5\u001b[0m adapt \u001b[39m=\u001b[39m AdaPT(\u001b[39m64\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m4\u001b[39m, [\u001b[39m2\u001b[39m], [\u001b[39m0.5\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'AdaPT_reloaded'"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adapt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
